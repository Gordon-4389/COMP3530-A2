{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gordon-4389/COMP3530-A2/blob/main/tutorials/VoiceSwapSample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wIWPxBVc3_O"
      },
      "source": [
        "# Getting Started: Voice swap application\n",
        "This notebook shows how to use NVIDIA NeMo (https://github.com/NVIDIA/NeMo) to construct a toy demo which will swap a voice in the audio fragment with a computer generated one.\n",
        "\n",
        "At its core the demo does:\n",
        "\n",
        "* Automatic speech recognition of what is said in the file. E.g. converting audio to text\n",
        "* Adding punctuation and capitalization to the text\n",
        "* Generating spectrogram from resulting text\n",
        "* Generating waveform audio from the spectrogram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzcsqceVdtj3"
      },
      "source": [
        "## Installation\n",
        "NeMo can be installed via simple pip command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9eIxAyKHREB",
        "outputId": "11733bdf-0921-4f62-f587-aba2279e30af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: git+https://github.com/NVIDIA/NeMo.git@r1.19.1#egg=nemo_toolkit[all] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nemo_toolkit[all]\n",
            "  Cloning https://github.com/NVIDIA/NeMo.git (to revision r1.19.1) to /tmp/pip-install-srfuthhd/nemo-toolkit_16ceb2a4e41f439db968bab9d39f09ff\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /tmp/pip-install-srfuthhd/nemo-toolkit_16ceb2a4e41f439db968bab9d39f09ff\n",
            "  Running command git checkout -b r1.19.1 --track origin/r1.19.1\n",
            "  Switched to a new branch 'r1.19.1'\n",
            "  Branch 'r1.19.1' set up to track remote branch 'r1.19.1' from 'origin'.\n",
            "  Resolved https://github.com/NVIDIA/NeMo.git to commit 55f8ce5a32ee2a2ec2c50c6df3eb8af585ea2fae\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting huggingface-hub (from nemo_toolkit[all])\n",
            "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.56.4)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.22.4)\n",
            "Collecting onnx>=1.7.0 (from nemo_toolkit[all])\n",
            "  Using cached onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.8.2)\n",
            "Collecting ruamel.yaml (from nemo_toolkit[all])\n",
            "  Using cached ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.2.2)\n",
            "Collecting setuptools==65.5.1 (from nemo_toolkit[all])\n",
            "  Using cached setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.12.3)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (4.65.0)\n",
            "Collecting wget (from nemo_toolkit[all])\n",
            "  Using cached wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.14.1)\n",
            "Collecting black==19.10b0 (from nemo_toolkit[all])\n",
            "  Using cached black-19.10b0-py36-none-any.whl (97 kB)\n",
            "Collecting click==8.0.2 (from nemo_toolkit[all])\n",
            "  Using cached click-8.0.2-py3-none-any.whl (97 kB)\n",
            "Collecting isort<6.0.0,>5.1.0 (from nemo_toolkit[all])\n",
            "  Using cached isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "Collecting parameterized (from nemo_toolkit[all])\n",
            "  Using cached parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (7.2.2)\n",
            "Collecting pytest-runner (from nemo_toolkit[all])\n",
            "  Using cached pytest_runner-6.0.0-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (3.5.4)\n",
            "Collecting sphinxcontrib-bibtex (from nemo_toolkit[all])\n",
            "  Using cached sphinxcontrib_bibtex-2.5.0-py3-none-any.whl (39 kB)\n",
            "Collecting wandb (from nemo_toolkit[all])\n",
            "  Using cached wandb-0.15.7-py3-none-any.whl (2.1 MB)\n",
            "Collecting hydra-core<1.3,>=1.2.0 (from nemo_toolkit[all])\n",
            "  Using cached hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "Collecting omegaconf<2.3,>=2.2 (from nemo_toolkit[all])\n",
            "  Using cached omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "Collecting pytorch-lightning<=1.9.4,>=1.9.0 (from nemo_toolkit[all])\n",
            "  Using cached pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "Collecting pyyaml<6 (from nemo_toolkit[all])\n",
            "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ],
      "source": [
        "BRANCH = 'r1.19.1'\n",
        "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-X2OyAxreGfl",
        "outputId": "2df5f797-03a7-4800-8abd-d1805af4bdd5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-57327be21084>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnemo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import Speech Recognition collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnemo_asr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nemo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Ignore pre-production warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nemo\n",
        "# Import Speech Recognition collection\n",
        "import nemo.collections.asr as nemo_asr\n",
        "# Import Natural Language Processing collection\n",
        "import nemo.collections.nlp as nemo_nlp\n",
        "# Import Speech Synthesis collection\n",
        "import nemo.collections.tts as nemo_tts\n",
        "# We'll use this to listen to audio\n",
        "import IPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vC2DHawIGt8"
      },
      "outputs": [],
      "source": [
        "# Download audio sample which we'll try\n",
        "# This is a sample from LibriSpeech Dev Clean dataset - the model hasn't seen it before\n",
        "Audio_sample = '2086-149220-0033.wav'\n",
        "!wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\n",
        "# Listen to it\n",
        "IPython.display.Audio(Audio_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zodyzdyTVXas"
      },
      "source": [
        "## Instantiate pre-trained NeMo models which we'll use\n",
        "``from_pretrained(...)`` API downloads and initialized model directly from the cloud.\n",
        "\n",
        "We will load audio_sample and convert it to text with QuartzNet ASR model (an action called transcribe).\n",
        "To convert text back to audio, we actually need to generate spectrogram with FastPitch first and then convert it to actual audio signal using the HiFiGAN vocoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_J9cuU1H6Bn"
      },
      "outputs": [],
      "source": [
        "# Speech Recognition model - QuartzNet\n",
        "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"stt_en_quartznet15x5\").cuda()\n",
        "\n",
        "# Punctuation and capitalization model\n",
        "punctuation = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name='punctuation_en_distilbert').cuda()\n",
        "\n",
        "# Spectrogram generator which takes text as an input and produces spectrogram\n",
        "spectrogram_generator = nemo_tts.models.FastPitchModel.from_pretrained(model_name=\"tts_en_fastpitch\").cuda()\n",
        "\n",
        "# Vocoder model which takes spectrogram and produces actual audio\n",
        "vocoder = nemo_tts.models.HifiGanModel.from_pretrained(model_name=\"tts_en_hifigan\").cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQSj-IhEhrtI"
      },
      "source": [
        "## Using the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0ERrXIzKpwu"
      },
      "outputs": [],
      "source": [
        "# Convert our audio sample to text\n",
        "files = [Audio_sample]\n",
        "raw_text = ''\n",
        "text = ''\n",
        "for fname, transcription in zip(files, quartznet.transcribe(paths2audio_files=files)):\n",
        "  raw_text = transcription\n",
        "\n",
        "# Add capitalization and punctuation\n",
        "res = punctuation.add_punctuation_capitalization(queries=[raw_text])\n",
        "text = res[0]\n",
        "print(f'\\nRaw recognized text: {raw_text}. \\nText with capitalization and punctuation: {text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0Sk0C9-LmAR"
      },
      "outputs": [],
      "source": [
        "# A helper function which combines TTS models to go directly from\n",
        "# text to audio\n",
        "def text_to_audio(text):\n",
        "  parsed = spectrogram_generator.parse(text)\n",
        "  spectrogram = spectrogram_generator.generate_spectrogram(tokens=parsed)\n",
        "  audio = vocoder.convert_spectrogram_to_audio(spec=spectrogram)\n",
        "  return audio.to('cpu').detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Jvwe4Ahncx"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-im5TDF-MP2N"
      },
      "outputs": [],
      "source": [
        "# This is our original audio sample\n",
        "IPython.display.Audio(Audio_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNOMquwviEEQ"
      },
      "outputs": [],
      "source": [
        "# This is what was recognized by the ASR model\n",
        "print(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qRpDPfNiLOU"
      },
      "outputs": [],
      "source": [
        "# This is how punctuation model changed it\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di2IzMsdiiWq"
      },
      "source": [
        "Compare how the synthesized audio sounds when using text with and without punctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIh8wTVs5uH7"
      },
      "outputs": [],
      "source": [
        "# Without punctuation\n",
        "IPython.display.Audio(text_to_audio(raw_text), rate=22050)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qgKa9L954bJ"
      },
      "outputs": [],
      "source": [
        "# Final result - with punctuation\n",
        "IPython.display.Audio(text_to_audio(text), rate=22050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOEFYywbctbJ"
      },
      "source": [
        "## Next steps\n",
        "A demo like this is great for prototyping and experimentation. However, for real production deployment, you would want to use a service like [NVIDIA Riva](https://developer.nvidia.com/riva).\n",
        "\n",
        "**NeMo is built for training.** You can fine-tune, or train from scratch on your data all models used in this example. We recommend you checkout the following, more in-depth, tutorials next:\n",
        "\n",
        "* [NeMo fundamentals](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/00_NeMo_Primer.ipynb)\n",
        "* [NeMo models](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/01_NeMo_Models.ipynb)\n",
        "* [Speech Recognition](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_NeMo.ipynb)\n",
        "* [Punctuation and Capitalization](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/nlp/Punctuation_and_Capitalization.ipynb)\n",
        "* [Speech Synthesis](https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/tts/Inference_ModelSelect.ipynb)\n",
        "\n",
        "\n",
        "You can find scripts for training and fine-tuning ASR, NLP and TTS models [here](https://github.com/NVIDIA/NeMo/tree/r1.19.0/examples)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahRh2Y0Lc0G1"
      },
      "source": [
        "That's it folks! Head over to NeMo GitHub for more examples: https://github.com/NVIDIA/NeMo"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NeMo voice swap app",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}